{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preliminaries\n","metadata":{"id":"dxqGaDrv1FVl"}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16)\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('ERROR')\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"id":"CnScC7CV0_69","outputId":"1ac0105d-eeda-4677-c43a-dd499734b932","execution":{"iopub.status.busy":"2022-01-07T10:39:19.451083Z","iopub.execute_input":"2022-01-07T10:39:19.451635Z","iopub.status.idle":"2022-01-07T10:39:19.459574Z","shell.execute_reply.started":"2022-01-07T10:39:19.451589Z","shell.execute_reply":"2022-01-07T10:39:19.458624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 1602\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"RIPjJWF81CQM","execution":{"iopub.status.busy":"2022-01-07T10:39:19.461559Z","iopub.execute_input":"2022-01-07T10:39:19.462063Z","iopub.status.idle":"2022-01-07T10:39:19.488398Z","shell.execute_reply.started":"2022-01-07T10:39:19.462027Z","shell.execute_reply":"2022-01-07T10:39:19.487607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CALLBACKS FUNCTION ADAPTED TO THIS NEW TASK\nfrom datetime import datetime\n\n#WE EXTEND THE CONCEPT OF CALLBACK BY COMBINING TWO AND OTHER STUFF WE NEED\ndef create_folders_and_callbacks(model_name):\n\n  exps_dir = os.path.join('experiments')\n  if not os.path.exists(exps_dir):\n      os.makedirs(exps_dir)\n\n  now = datetime.now().strftime('%b%d_%H-%M-%S') #DATE GENERATION\n\n  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now)) #WE ADD THE DATE TO THE NAME SO THAT WE CAN MONITOR AND COMAPRE RESULTS\n  if not os.path.exists(exp_dir):\n      os.makedirs(exp_dir)\n      \n  callbacks = []\n\n  # Model checkpoint\n  # ----------------\n  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n  if not os.path.exists(ckpt_dir):\n      os.makedirs(ckpt_dir)\n\n  #THIS FUNCTION ALLOWS TO SAVE THE MODEL DURING TRAINING\n  #TAKES AS ARGUMENT WHERE WE WANT TO SAVE\n  #BETTER TO SAVE ENTIRE MODEL AND NOT ONLY THE WEIGHTS\n  #PUT SAVEBESTONLY TO FALSE, IT WILL SAVE THE LAST ONE\n  #YOU CAN SAVE BEST BY USING EARLYSTOPPING! DONE BELOW\n  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n                                                     save_weights_only=False, # True to save only weights\n                                                     save_best_only=False) # True to save only the best epoch \n  callbacks.append(ckpt_callback)\n\n  # Visualize Learning on Tensorboard\n  # ---------------------------------\n  tb_dir = os.path.join(exp_dir, 'tb_logs')\n  if not os.path.exists(tb_dir):\n      os.makedirs(tb_dir)\n      \n  # By default shows losses and metrics for both training and validation\n  #THIS WILL SAVE INFO ON THE METRICS ETC.\n  #LOG DIR IS WHERE WE SAVE THE INFO\n  #PROFILE BATCH TO ZERO HELPS REDUCE TIME\n  #HISTOGRAM FREQ TELLS ON HOW MANY EPOCHS YOU NEED TO SAVE RESULTS\n  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n                                               profile_batch=0,\n                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n  callbacks.append(tb_callback)\n\n  # Early Stopping\n  # --------------\n  es_callback = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n  callbacks.append(es_callback)\n  rop_callback =  tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n  callbacks.append(rop_callback)\n  return callbacks","metadata":{"id":"4viV_VxaokSX","execution":{"iopub.status.busy":"2022-01-07T10:39:19.490328Z","iopub.execute_input":"2022-01-07T10:39:19.49111Z","iopub.status.idle":"2022-01-07T10:39:19.503774Z","shell.execute_reply.started":"2022-01-07T10:39:19.491071Z","shell.execute_reply":"2022-01-07T10:39:19.503006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading \n\n","metadata":{"id":"4d4L2trs1Kts"}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/dataset/dataset.csv')\nprint(dataset.shape)\ndataset.head()\n#WE LOAD DATA AND HAVE A LOOK AT SOME SAMPLES","metadata":{"id":"Mh9t2km81PrI","outputId":"623ecc04-80dc-4a25-87ce-40bed2e827dc","execution":{"iopub.status.busy":"2022-01-07T10:39:19.504949Z","iopub.execute_input":"2022-01-07T10:39:19.505333Z","iopub.status.idle":"2022-01-07T10:39:19.632843Z","shell.execute_reply.started":"2022-01-07T10:39:19.505297Z","shell.execute_reply":"2022-01-07T10:39:19.632025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info() \n#VARIABLES INFO","metadata":{"id":"vPSQnL_a18qN","outputId":"9f9cca00-8c6d-409c-c5b8-08ac4c7951d6","execution":{"iopub.status.busy":"2022-01-07T10:39:19.635117Z","iopub.execute_input":"2022-01-07T10:39:19.635382Z","iopub.status.idle":"2022-01-07T10:39:19.648916Z","shell.execute_reply.started":"2022-01-07T10:39:19.635346Z","shell.execute_reply":"2022-01-07T10:39:19.648183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization\n","metadata":{"id":"9lf8x_Pn30he"}},{"cell_type":"code","source":"#A FUNCTION TO PLOT THE SERIES\ndef inspect_dataframe(df, columns):\n    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n    for i, col in enumerate(columns):\n        axs[i].plot(df[col])\n        axs[i].set_title(col)\n    plt.show()","metadata":{"id":"uTqGXH022E4m","execution":{"iopub.status.busy":"2022-01-07T10:39:19.650208Z","iopub.execute_input":"2022-01-07T10:39:19.650462Z","iopub.status.idle":"2022-01-07T10:39:19.655727Z","shell.execute_reply.started":"2022-01-07T10:39:19.650428Z","shell.execute_reply":"2022-01-07T10:39:19.654783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_dataframe(dataset, dataset.columns) #WE VISUALIZE THE TRENDS IN THE VARIABLES ","metadata":{"id":"-iYNax6t2H1V","outputId":"f270c1cc-32a8-4cb6-c540-6ac79eb3b8db","execution":{"iopub.status.busy":"2022-01-07T10:39:19.657117Z","iopub.execute_input":"2022-01-07T10:39:19.657601Z","iopub.status.idle":"2022-01-07T10:39:20.551514Z","shell.execute_reply.started":"2022-01-07T10:39:19.657566Z","shell.execute_reply":"2022-01-07T10:39:20.550841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting\n","metadata":{"id":"YniSyVLl3-Lz"}},{"cell_type":"code","source":"#THE LAST SAMPLES OF THE GIVEN SERIES ARE USED FOR TESTING,\n#THE NUMBER IS CHOSEN USING SAME PROPORTION USED BY LATTARI (CIRCA 9%)\ntest_size = 6500\nX_train_raw = dataset.iloc[:-test_size]\n# y_train_raw = y.iloc[:-test_size]\nX_test_raw = dataset.iloc[-test_size:]\n# y_test_raw = y.iloc[-test_size:]\nprint(X_train_raw.shape, X_test_raw.shape)\n\n# Normalize both features and labels\nX_min = X_train_raw.min()\nX_max = X_train_raw.max()\n\n#THEN WE NORMALIZE IN 0 1 RANGE\nX_train_raw = (X_train_raw-X_min)/(X_max-X_min)\nX_test_raw = (X_test_raw-X_min)/(X_max-X_min)\n\nplt.figure(figsize=(17,5))\nplt.plot(X_train_raw.Sponginess, label='Train (Sponginess)')\nplt.plot(X_test_raw.Sponginess, label='Test (Sponginess)')\nplt.title('Train-Test Split')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(17,5))\nplt.plot(X_train_raw.Crunchiness, label='Train (Crunchiness)')\nplt.plot(X_test_raw.Crunchiness, label='Test (Crunchiness)')\nplt.title('Train-Test Split')\nplt.legend()\nplt.show()\n","metadata":{"id":"ryd2qBQh28NO","outputId":"cd0d2ca1-f339-4849-b04c-bc978158604d","execution":{"iopub.status.busy":"2022-01-07T10:39:20.552856Z","iopub.execute_input":"2022-01-07T10:39:20.553583Z","iopub.status.idle":"2022-01-07T10:39:21.465664Z","shell.execute_reply.started":"2022-01-07T10:39:20.553542Z","shell.execute_reply":"2022-01-07T10:39:21.464904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Sequences (Direct Forecasting)","metadata":{"id":"aRvdbm0d5cVd"}},{"cell_type":"code","source":"window = 2400\nstride = 10","metadata":{"id":"KqSfgP5E4Vjs","execution":{"iopub.status.busy":"2022-01-07T10:39:21.467065Z","iopub.execute_input":"2022-01-07T10:39:21.467866Z","iopub.status.idle":"2022-01-07T10:39:21.475869Z","shell.execute_reply.started":"2022-01-07T10:39:21.467826Z","shell.execute_reply":"2022-01-07T10:39:21.475144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#THIS WILL BE USED AT END OF THE NOTEBOOK AND IS THE VERY LAST SEQUENCE AT THE END OF THE DATASET\n#WILL BE USED AS STARTING POINT TO PREDICT THE FUTURE\n\nfuture = dataset[-window:]\nfuture = (future-X_min)/(X_max-X_min)\nfuture = np.expand_dims(future, axis=0)\nfuture.shape","metadata":{"id":"pUUyiiV44ZZr","outputId":"abbcd56d-d4ed-414a-a1f8-20eedc99f648","execution":{"iopub.status.busy":"2022-01-07T10:39:21.477292Z","iopub.execute_input":"2022-01-07T10:39:21.482445Z","iopub.status.idle":"2022-01-07T10:39:21.493116Z","shell.execute_reply.started":"2022-01-07T10:39:21.482404Z","shell.execute_reply":"2022-01-07T10:39:21.492255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_sequences(df, target_labels=['Sponginess'], window=200, stride=20, telescope=100):\n    # Sanity check to avoid runtime errors\n    assert window % stride == 0\n    dataset = []\n    labels = []\n    temp_df = df.copy().values\n    temp_label = df[target_labels].copy().values\n    padding_len = len(df)%window\n\n    if(padding_len != 0):\n        # Compute padding length\n        padding_len = window - len(df)%window\n        padding = np.zeros((padding_len,temp_df.shape[1]), dtype='float64')\n        temp_df = np.concatenate((padding,df))\n        padding = np.zeros((padding_len,temp_label.shape[1]), dtype='float64')\n        temp_label = np.concatenate((padding,temp_label))\n        assert len(temp_df) % window == 0\n\n    for idx in np.arange(0,len(temp_df)-window-telescope,stride):\n        dataset.append(temp_df[idx:idx+window])\n        labels.append(temp_label[idx+window:idx+window+telescope])\n\n    dataset = np.array(dataset)\n    labels = np.array(labels)\n    return dataset, labels","metadata":{"id":"gi_ZTV6P4f_E","execution":{"iopub.status.busy":"2022-01-07T10:39:21.498466Z","iopub.execute_input":"2022-01-07T10:39:21.498732Z","iopub.status.idle":"2022-01-07T10:39:21.51333Z","shell.execute_reply.started":"2022-01-07T10:39:21.498687Z","shell.execute_reply":"2022-01-07T10:39:21.51258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_labels = dataset.columns #WE TAKE ALL COLUMNS AS LABELS\ntelescope = 864","metadata":{"id":"jJN0OlGk42al","execution":{"iopub.status.busy":"2022-01-07T10:39:21.517441Z","iopub.execute_input":"2022-01-07T10:39:21.519528Z","iopub.status.idle":"2022-01-07T10:39:21.527303Z","shell.execute_reply.started":"2022-01-07T10:39:21.519473Z","shell.execute_reply":"2022-01-07T10:39:21.52649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\nX_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, telescope)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape\n\n#WE CAN SEE DIMENSION OF THE CUTS AND THE DIMENSIONS OF WHAT WE WANT TO PREDICT ","metadata":{"id":"h6peDuos44im","outputId":"cbe2258a-6094-4779-9bbd-45fda895cf1f","execution":{"iopub.status.busy":"2022-01-07T10:39:21.532165Z","iopub.execute_input":"2022-01-07T10:39:21.53453Z","iopub.status.idle":"2022-01-07T10:39:21.864588Z","shell.execute_reply.started":"2022-01-07T10:39:21.532527Z","shell.execute_reply":"2022-01-07T10:39:21.863885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#WE CAN SEE SOME EXAMPLES OF WINDOWS(?) \ndef inspect_multivariate(X, y, columns, telescope, idx=None):\n    if(idx==None):\n        idx=np.random.randint(0,len(X))\n\n    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n    for i, col in enumerate(columns):\n        axs[i].plot(np.arange(len(X[0,:,i])), X[idx,:,i])\n        axs[i].scatter(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), y[idx,:,i], color='orange')\n        axs[i].set_title(col)\n        axs[i].set_ylim(0,1)\n    plt.show()","metadata":{"id":"Cmj5NMzE4sc-","execution":{"iopub.status.busy":"2022-01-07T10:39:21.866073Z","iopub.execute_input":"2022-01-07T10:39:21.866485Z","iopub.status.idle":"2022-01-07T10:39:21.874678Z","shell.execute_reply.started":"2022-01-07T10:39:21.866447Z","shell.execute_reply":"2022-01-07T10:39:21.873837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_multivariate(X_train, y_train, target_labels, telescope)","metadata":{"id":"g5sOyLNB4uu0","outputId":"6d5f7d34-6709-46d8-8b53-2cf431872cf3","execution":{"iopub.status.busy":"2022-01-07T10:39:21.87758Z","iopub.execute_input":"2022-01-07T10:39:21.877813Z","iopub.status.idle":"2022-01-07T10:39:24.048374Z","shell.execute_reply.started":"2022-01-07T10:39:21.877788Z","shell.execute_reply":"2022-01-07T10:39:24.046611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Model\n","metadata":{"id":"a2OBPfMy5jsU"}},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\noutput_shape = y_train.shape[1:]\nbatch_size = 64\nepochs = 200\nprint(\"output shape is\", output_shape)\nprint(\"input shape is\", input_shape)","metadata":{"id":"Hpwub1dT5Z9d","outputId":"a9a9ad96-856d-417c-9f64-1893e2b85f19","execution":{"iopub.status.busy":"2022-01-07T10:39:24.04986Z","iopub.execute_input":"2022-01-07T10:39:24.050385Z","iopub.status.idle":"2022-01-07T10:39:24.056625Z","shell.execute_reply.started":"2022-01-07T10:39:24.050348Z","shell.execute_reply":"2022-01-07T10:39:24.055849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_CONV_LSTM_model(input_shape, output_shape):\n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    #HERE WE START WITH A BIDIRECTIONAL AND WE PUT ALSO CONVO \n    #CONVO CAPTURES SPATIAL CORRELATIONS\n    #LSTM CAPTURES BETTER THE TEMPORAL CORRELATIONS\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(256, return_sequences=True))(input_layer)\n    #convlstm = tfkl.Conv1D(128, 3, padding='same', activation='relu')(convlstm)\n    convlstm = tfkl.MaxPool1D()(convlstm)\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(512, return_sequences=True))(convlstm)\n    #convlstm = tfkl.Conv1D(256, 3, padding='same', activation='relu')(convlstm)\n    #convlstm = tfkl.Conv1D(512, 3, padding='same', activation='relu')(convlstm)\n    convlstm = tfkl.GlobalAveragePooling1D()(convlstm)\n    convlstm = tfkl.Dropout(.3)(convlstm)\n\n    dense = tfkl.Dense(output_shape[-1]*output_shape[-2], activation='relu')(convlstm)\n    output_layer = tfkl.Reshape((output_shape[-2],output_shape[-1]))(dense)\n    output_layer = tfkl.Conv1D(output_shape[-1], 1, padding='same')(output_layer)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=['mae'])\n\n    # Return the model\n    return model","metadata":{"id":"kGtCi9-O5qLF","execution":{"iopub.status.busy":"2022-01-07T10:39:24.05908Z","iopub.execute_input":"2022-01-07T10:39:24.059559Z","iopub.status.idle":"2022-01-07T10:39:24.071384Z","shell.execute_reply.started":"2022-01-07T10:39:24.059524Z","shell.execute_reply":"2022-01-07T10:39:24.070598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_CONV_LSTM_model(input_shape, output_shape)\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True)\n","metadata":{"id":"0D9skNYS51I9","outputId":"5504b4bb-292d-4f29-d839-f3a66f85d200","execution":{"iopub.status.busy":"2022-01-07T10:39:24.072792Z","iopub.execute_input":"2022-01-07T10:39:24.073084Z","iopub.status.idle":"2022-01-07T10:39:25.368695Z","shell.execute_reply.started":"2022-01-07T10:39:24.073047Z","shell.execute_reply":"2022-01-07T10:39:25.367875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"direct_callbacks = create_folders_and_callbacks(\"Direct864_first\")","metadata":{"id":"ld6AK4D7RZg8","execution":{"iopub.status.busy":"2022-01-07T10:39:25.370609Z","iopub.execute_input":"2022-01-07T10:39:25.371047Z","iopub.status.idle":"2022-01-07T10:39:25.376356Z","shell.execute_reply.started":"2022-01-07T10:39:25.371006Z","shell.execute_reply":"2022-01-07T10:39:25.37552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n\"\"\"\nhistory = model.fit(\n    x = X_train,\n    y = y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_split=.1,\n    callbacks = direct_callbacks\n).history\n\"\"\"","metadata":{"id":"kkn9Q59C58c7","outputId":"83775af7-36f3-4fd7-d8e3-29d6218ea47d","execution":{"iopub.status.busy":"2022-01-07T10:39:25.377911Z","iopub.execute_input":"2022-01-07T10:39:25.378227Z","iopub.status.idle":"2022-01-07T10:39:25.387311Z","shell.execute_reply.started":"2022-01-07T10:39:25.378147Z","shell.execute_reply":"2022-01-07T10:39:25.386337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nbest_epoch = np.argmin(history['val_loss'])\nplt.figure(figsize=(17,4))\nplt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.title('Mean Squared Error (Loss)')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(17,4))\nplt.plot(history['mae'], label='Training accuracy', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_mae'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.title('Mean Absolute Error')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(18,3))\nplt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\n\"\"\"","metadata":{"id":"C2SZa9pQDorq","execution":{"iopub.status.busy":"2022-01-07T10:39:25.389074Z","iopub.execute_input":"2022-01-07T10:39:25.389333Z","iopub.status.idle":"2022-01-07T10:39:25.399465Z","shell.execute_reply.started":"2022-01-07T10:39:25.389299Z","shell.execute_reply":"2022-01-07T10:39:25.398714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('experiments/DirectForecasting')","metadata":{"id":"g9DGWdhCDpYx","execution":{"iopub.status.busy":"2022-01-07T10:39:25.400748Z","iopub.execute_input":"2022-01-07T10:39:25.401705Z","iopub.status.idle":"2022-01-07T10:39:45.845709Z","shell.execute_reply.started":"2022-01-07T10:39:25.401676Z","shell.execute_reply":"2022-01-07T10:39:45.844973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ModelTesting\n","metadata":{"id":"JwSIHljEkOdn"}},{"cell_type":"code","source":"#model = tfk.models.load_model('experiments/DirectForecasting')","metadata":{"id":"-LZM2y2-jqOo","execution":{"iopub.status.busy":"2022-01-07T10:39:45.848656Z","iopub.execute_input":"2022-01-07T10:39:45.848926Z","iopub.status.idle":"2022-01-07T10:39:45.852448Z","shell.execute_reply.started":"2022-01-07T10:39:45.848871Z","shell.execute_reply":"2022-01-07T10:39:45.851786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set \npredictions = model.predict(X_test)\nprint(predictions.shape)\n#WE COMPUTE METRICS FOR THE TEST\nmean_squared_error = tfk.metrics.mse(y_test.flatten(),predictions.flatten())\nmean_absolute_error = tfk.metrics.mae(y_test.flatten(),predictions.flatten())\nmean_squared_error, mean_absolute_error","metadata":{"id":"dx7g4Frtj9y3","execution":{"iopub.status.busy":"2022-01-07T10:39:45.853765Z","iopub.execute_input":"2022-01-07T10:39:45.854216Z","iopub.status.idle":"2022-01-07T10:39:52.039568Z","shell.execute_reply.started":"2022-01-07T10:39:45.854182Z","shell.execute_reply":"2022-01-07T10:39:52.038778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to inspect our predictions compared to the test set\ndef inspect_multivariate_prediction(X, y, pred, columns, telescope, idx=None):\n    if(idx==None):\n        idx=np.random.randint(0,len(X))\n\n    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n    for i, col in enumerate(columns):\n        axs[i].plot(np.arange(len(X[0,:,i])), X[idx,:,i])\n        axs[i].scatter(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), y[idx,:,i], color='orange')\n        axs[i].scatter(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), pred[idx,:,i], color='green')\n        axs[i].set_title(col)\n        axs[i].set_ylim(0,1)\n    plt.show()","metadata":{"id":"JjKdpnMVkCdH","execution":{"iopub.status.busy":"2022-01-07T10:39:52.041068Z","iopub.execute_input":"2022-01-07T10:39:52.041345Z","iopub.status.idle":"2022-01-07T10:39:52.050324Z","shell.execute_reply.started":"2022-01-07T10:39:52.041309Z","shell.execute_reply":"2022-01-07T10:39:52.04947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BY RERUNNING CELL WE WILL SEE DIFERRENT WINDOWS \ninspect_multivariate_prediction(X_test, y_test, predictions, target_labels, telescope)","metadata":{"id":"MVxwJPULkE_n","execution":{"iopub.status.busy":"2022-01-07T10:39:52.051774Z","iopub.execute_input":"2022-01-07T10:39:52.052057Z","iopub.status.idle":"2022-01-07T10:39:52.907784Z","shell.execute_reply.started":"2022-01-07T10:39:52.052022Z","shell.execute_reply":"2022-01-07T10:39:52.907118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sequences (AutoReg)\n","metadata":{"id":"bYP0yCpLmybW"}},{"cell_type":"code","source":"target_labels = dataset.columns\nwindow = 600\ntelescope = 8 \n#WE WANT TO LEARN ONLY ONE VALUE AT A TIME\nX_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\nX_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, telescope)\n#WE PRINT THE SHAPES OF OUR TRAIN AND TEST SEQUENCES\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"id":"pOdu3yhTm3g6","execution":{"iopub.status.busy":"2022-01-07T10:39:52.908996Z","iopub.execute_input":"2022-01-07T10:39:52.909568Z","iopub.status.idle":"2022-01-07T10:39:53.009243Z","shell.execute_reply.started":"2022-01-07T10:39:52.909527Z","shell.execute_reply":"2022-01-07T10:39:53.008384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_multivariate(X_train, y_train, target_labels, telescope)\n#THE YELLOW POINT IS WHAT WE WANT TO PREDICT","metadata":{"id":"c1PO4L7cnBX3","execution":{"iopub.status.busy":"2022-01-07T10:39:53.010788Z","iopub.execute_input":"2022-01-07T10:39:53.011072Z","iopub.status.idle":"2022-01-07T10:39:53.745815Z","shell.execute_reply.started":"2022-01-07T10:39:53.011036Z","shell.execute_reply":"2022-01-07T10:39:53.745176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\noutput_shape = y_train.shape[1:]\nbatch_size = 64\nepochs = 100\nprint(\"output shape is\", output_shape)\nprint(\"input shape is\", input_shape)","metadata":{"id":"soDvHEsinHGw","execution":{"iopub.status.busy":"2022-01-07T10:39:53.750093Z","iopub.execute_input":"2022-01-07T10:39:53.750457Z","iopub.status.idle":"2022-01-07T10:39:53.75803Z","shell.execute_reply.started":"2022-01-07T10:39:53.750425Z","shell.execute_reply":"2022-01-07T10:39:53.757031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model (Autoreg)","metadata":{"id":"OUeH5-1coJdm"}},{"cell_type":"code","source":"def build_CONV_LSTM_model(input_shape, output_shape):\n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    #HERE WE START WITH A BIDIRECTIONAL AND WE PUT ALSO CONVO \n    #CONVO CAPTURES SPATIAL CORRELATIONS\n    #LSTM CAPTURES BETTER THE TEMPORAL CORRELATIONS\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(256, return_sequences=True))(input_layer)\n    #convlstm = tfkl.Conv1D(128, 3, padding='same', activation='relu')(convlstm)\n    convlstm = tfkl.MaxPool1D()(convlstm)\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(512, return_sequences=True))(convlstm)\n    #convlstm = tfkl.Conv1D(256, 3, padding='same', activation='relu')(convlstm)\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(1024, return_sequences=True))(convlstm)\n    convlstm = tfkl.GlobalAveragePooling1D()(convlstm)\n    convlstm = tfkl.Dropout(.3)(convlstm)\n\n    dense = tfkl.Dense(output_shape[-1]*output_shape[-2], activation='relu')(convlstm)\n    output_layer = tfkl.Reshape((output_shape[-2],output_shape[-1]))(dense)\n    output_layer = tfkl.Conv1D(output_shape[-1], 1, padding='same')(output_layer)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=['mae'])\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-07T10:39:53.759702Z","iopub.execute_input":"2022-01-07T10:39:53.761374Z","iopub.status.idle":"2022-01-07T10:39:53.771093Z","shell.execute_reply.started":"2022-01-07T10:39:53.761344Z","shell.execute_reply":"2022-01-07T10:39:53.770249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_CONV_LSTM_model(input_shape, output_shape)\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True)","metadata":{"id":"VV5hJ2tznjR-","execution":{"iopub.status.busy":"2022-01-07T10:39:53.772394Z","iopub.execute_input":"2022-01-07T10:39:53.772721Z","iopub.status.idle":"2022-01-07T10:39:57.532569Z","shell.execute_reply.started":"2022-01-07T10:39:53.772684Z","shell.execute_reply":"2022-01-07T10:39:57.531713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auto_callbacks = create_folders_and_callbacks(\"Autoreg_first\")\nprint(auto_callbacks)","metadata":{"id":"naEjujBOpD4W","execution":{"iopub.status.busy":"2022-01-07T10:39:57.534601Z","iopub.execute_input":"2022-01-07T10:39:57.534863Z","iopub.status.idle":"2022-01-07T10:39:57.540677Z","shell.execute_reply.started":"2022-01-07T10:39:57.534825Z","shell.execute_reply":"2022-01-07T10:39:57.540006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n\"\"\"\nhistory = model.fit(\n    x = X_train,\n    y = y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_split=.1,\n    callbacks = auto_callbacks\n).history\n\"\"\"","metadata":{"id":"QaYixcfZoHhe","execution":{"iopub.status.busy":"2022-01-07T10:39:57.542177Z","iopub.execute_input":"2022-01-07T10:39:57.54267Z","iopub.status.idle":"2022-01-07T10:39:57.553643Z","shell.execute_reply.started":"2022-01-07T10:39:57.542633Z","shell.execute_reply":"2022-01-07T10:39:57.552891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nbest_epoch = np.argmin(history['val_loss'])\nplt.figure(figsize=(17,4))\nplt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.title('Mean Squared Error (Loss)')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(17,4))\nplt.plot(history['mae'], label='Training accuracy', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_mae'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.title('Mean Absolute Error')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(18,3))\nplt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\nplt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\"\"\"","metadata":{"id":"nz7wsRtbIQTF","execution":{"iopub.status.busy":"2022-01-07T10:39:57.55493Z","iopub.execute_input":"2022-01-07T10:39:57.555913Z","iopub.status.idle":"2022-01-07T10:39:57.563559Z","shell.execute_reply.started":"2022-01-07T10:39:57.555874Z","shell.execute_reply":"2022-01-07T10:39:57.5628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('experiments/Autoreg_BestWeights')\n#model = tfk.models.load_model('experiments/Autoreg_BestWeights')","metadata":{"id":"RZi-OpM05Iqk","execution":{"iopub.status.busy":"2022-01-07T10:39:57.564803Z","iopub.execute_input":"2022-01-07T10:39:57.565534Z","iopub.status.idle":"2022-01-07T10:40:28.444281Z","shell.execute_reply.started":"2022-01-07T10:39:57.565477Z","shell.execute_reply":"2022-01-07T10:40:28.443481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set \npredictions = model.predict(X_test)\nprint(predictions.shape)\n\nmean_squared_error = tfk.metrics.mse(y_test.flatten(),predictions.flatten())\nmean_absolute_error = tfk.metrics.mae(y_test.flatten(),predictions.flatten())\nmean_squared_error, mean_absolute_error","metadata":{"id":"TXLPsq_ZIJKo","execution":{"iopub.status.busy":"2022-01-07T10:40:28.447603Z","iopub.execute_input":"2022-01-07T10:40:28.447932Z","iopub.status.idle":"2022-01-07T10:40:32.636614Z","shell.execute_reply.started":"2022-01-07T10:40:28.4479Z","shell.execute_reply":"2022-01-07T10:40:32.635871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_multivariate_prediction(X_test, y_test, predictions, target_labels, telescope)\n#THE PREDICTIONS (GREEN) ARE QUITE SIMILAR!","metadata":{"id":"QLSgyj7LIfWW","execution":{"iopub.status.busy":"2022-01-07T10:40:32.637862Z","iopub.execute_input":"2022-01-07T10:40:32.638201Z","iopub.status.idle":"2022-01-07T10:40:33.450186Z","shell.execute_reply.started":"2022-01-07T10:40:32.638164Z","shell.execute_reply":"2022-01-07T10:40:33.448774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I TRIED TO LEARN THE 100 NEXT FROM THE MODEL MADE TO LEARN ONLY THE NEXT VALUE\nreg_telescope = 864\nX_test_reg, y_test_reg = build_sequences(X_test_raw, target_labels, window, stride, reg_telescope)\nX_test_reg.shape, y_test_reg.shape","metadata":{"id":"T8-uEhZEIqd-","execution":{"iopub.status.busy":"2022-01-07T10:40:33.451677Z","iopub.execute_input":"2022-01-07T10:40:33.452127Z","iopub.status.idle":"2022-01-07T10:40:33.471696Z","shell.execute_reply.started":"2022-01-07T10:40:33.452092Z","shell.execute_reply":"2022-01-07T10:40:33.470934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nreg_predictions = np.array([])\nX_temp = X_test_reg\nprint(X_temp.shape)\nfor reg in range(int(reg_telescope/telescope)):\n    pred_temp = model.predict(X_temp)\n    if(len(reg_predictions)==0):\n        reg_predictions = pred_temp\n    else:\n        reg_predictions = np.concatenate((reg_predictions,pred_temp),axis=1) #I CONCATE THE LAST PREDICTION WITH THE PREVIOUS ONES\n    X_temp = np.concatenate((X_temp[:,telescope:,:], pred_temp), axis=1)","metadata":{"id":"b8xlNh64Iw8X","execution":{"iopub.status.busy":"2022-01-07T10:40:33.473136Z","iopub.execute_input":"2022-01-07T10:40:33.473403Z","iopub.status.idle":"2022-01-07T10:45:02.819676Z","shell.execute_reply.started":"2022-01-07T10:40:33.473366Z","shell.execute_reply":"2022-01-07T10:45:02.818867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_predictions.shape","metadata":{"id":"xkRmjlO2Iznx","execution":{"iopub.status.busy":"2022-01-07T10:45:02.821259Z","iopub.execute_input":"2022-01-07T10:45:02.821524Z","iopub.status.idle":"2022-01-07T10:45:02.82699Z","shell.execute_reply.started":"2022-01-07T10:45:02.821489Z","shell.execute_reply":"2022-01-07T10:45:02.826136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error = tfk.metrics.mse(y_test_reg.flatten(),reg_predictions.flatten())\nmean_absolute_error = tfk.metrics.mae(y_test_reg.flatten(),reg_predictions.flatten())\nmean_squared_error, mean_absolute_error","metadata":{"id":"jxWYbKvEI1Ko","execution":{"iopub.status.busy":"2022-01-07T10:45:02.828612Z","iopub.execute_input":"2022-01-07T10:45:02.829226Z","iopub.status.idle":"2022-01-07T10:45:02.899545Z","shell.execute_reply.started":"2022-01-07T10:45:02.829183Z","shell.execute_reply":"2022-01-07T10:45:02.898833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inspect_multivariate_prediction(X_test_reg, y_test_reg, reg_predictions, target_labels, reg_telescope)","metadata":{"id":"24rnilD1I3xe","execution":{"iopub.status.busy":"2022-01-07T10:45:02.900712Z","iopub.execute_input":"2022-01-07T10:45:02.900971Z","iopub.status.idle":"2022-01-07T10:45:03.759929Z","shell.execute_reply.started":"2022-01-07T10:45:02.900923Z","shell.execute_reply":"2022-01-07T10:45:03.759301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer Tentative (seen at lecture)\n","metadata":{}},{"cell_type":"code","source":"#seen from lecture \nfrom transformes import Automodel, AutoTokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Automodel.from_pretrained()\ntokenizer = AutoTokenizer.from_pretrained()\n\n#NO INSTRUMENTS FROM THIS TASK SEEM TO BE THERE!","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer tentative (with repo)","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/nklingen/Transformer-Time-Series-Forecasting","metadata":{"execution":{"iopub.status.busy":"2022-01-07T11:09:21.661657Z","iopub.execute_input":"2022-01-07T11:09:21.662505Z","iopub.status.idle":"2022-01-07T11:09:23.200192Z","shell.execute_reply.started":"2022-01-07T11:09:21.662462Z","shell.execute_reply":"2022-01-07T11:09:23.19933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install icecream","metadata":{"execution":{"iopub.status.busy":"2022-01-07T11:15:10.06402Z","iopub.execute_input":"2022-01-07T11:15:10.064879Z","iopub.status.idle":"2022-01-07T11:15:18.481746Z","shell.execute_reply.started":"2022-01-07T11:15:10.06484Z","shell.execute_reply":"2022-01-07T11:15:18.480926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd \"/kaggle/working/Transformer-Time-Series-Forecasting/\"\nfrom train_with_sampling import *\nfrom DataLoader import*","metadata":{"execution":{"iopub.status.busy":"2022-01-07T11:17:36.037437Z","iopub.execute_input":"2022-01-07T11:17:36.038033Z","iopub.status.idle":"2022-01-07T11:17:36.043818Z","shell.execute_reply.started":"2022-01-07T11:17:36.037997Z","shell.execute_reply":"2022-01-07T11:17:36.043028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader= DataLoader(X_train_raw, batch_size=1, shuffle=True)\ntest_dataloader = DataLoader(X_test_raw, batch_size=1, shuffle=True)\nprint(test_dataloader)\nprint(\"ok\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T11:24:38.988408Z","iopub.execute_input":"2022-01-07T11:24:38.988715Z","iopub.status.idle":"2022-01-07T11:24:39.000139Z","shell.execute_reply.started":"2022-01-07T11:24:38.988682Z","shell.execute_reply":"2022-01-07T11:24:38.998923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_save_model = \"/kaggle/working/experiments/transformer\"\npath_to_save_loss = \"/kaggle/working/experiments/transformer\"\npath_to_save_predictions = \"/kaggle/working/experiments/transformer\"\ndevice= \"cpu\"\nforecast_window = 864\nepoch = 100\nk = 60\nfrequency = 100","metadata":{"execution":{"iopub.status.busy":"2022-01-07T11:23:34.60672Z","iopub.execute_input":"2022-01-07T11:23:34.607026Z","iopub.status.idle":"2022-01-07T11:23:34.613494Z","shell.execute_reply.started":"2022-01-07T11:23:34.606991Z","shell.execute_reply":"2022-01-07T11:23:34.612509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = transformer(train_dataloader, epoch, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device)\ninference(path_to_save_predictions, forecast_window, test_dataloader, device, path_to_save_model, best_model)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T11:23:36.55094Z","iopub.execute_input":"2022-01-07T11:23:36.551559Z","iopub.status.idle":"2022-01-07T11:23:36.688084Z","shell.execute_reply.started":"2022-01-07T11:23:36.551522Z","shell.execute_reply":"2022-01-07T11:23:36.686822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer (adapting repo) ","metadata":{}},{"cell_type":"markdown","source":"Using same repo imported before, copied and had a look at the code to see if i could make it work at least","metadata":{}},{"cell_type":"code","source":"#LIBRARIES IMPORTED ONLY TO SEE IF STUFF WORKS, WAS NOT ABLE TO ADAPT IT\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import MinMaxScaler\nimport torch\nimport matplotlib.pyplot as plt\nfrom joblib import dump\nimport logging\nimport time # debugging\nfrom plot import *\nfrom helpers import *\nfrom joblib import load\nfrom icecream import ic\nimport torch.nn as nn\nimport math\nimport time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nclass SensorDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, csv_name, root_dir, training_length, forecast_window):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file.\n            root_dir (string): Directory\n        \"\"\"\n        \n        # load raw data file\n        csv_file = os.path.join(root_dir, csv_name)\n        self.df = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = MinMaxScaler()\n        self.T = training_length\n        self.S = forecast_window\n\n    def __len__(self):\n        # return number of sensors\n        return len(self.df.groupby(by=[\"reindexed_id\"]))\n\n    # Will pull an index between 0 and __len__. \n    def __getitem__(self, idx):\n        \n        # Sensors are indexed from 1\n        idx = idx+1\n\n        # np.random.seed(0)\n\n        start = np.random.randint(0, len(self.df[self.df[\"reindexed_id\"]==idx]) - self.T - self.S) \n        sensor_number = str(self.df[self.df[\"reindexed_id\"]==idx][[\"sensor_id\"]][start:start+1].values.item())\n        #NEED TO CHANGE ALL OF THIS, ALSO PARAMS ARE THE ONE RELATED TO THE ORIGINAL PROBLEM\n        \"\"\"\n        index_in = torch.tensor([i for i in range(start, start+self.T)])\n        index_tar = torch.tensor([i for i in range(start + self.T, start + self.T + self.S)])\n        _input = torch.tensor(self.df[self.df[\"reindexed_id\"]==idx][[\"humidity\", \"sin_hour\", \"cos_hour\", \"sin_day\", \"cos_day\", \"sin_month\", \"cos_month\"]][start : start + self.T].values)\n        target = torch.tensor(self.df[self.df[\"reindexed_id\"]==idx][[\"humidity\", \"sin_hour\", \"cos_hour\", \"sin_day\", \"cos_day\", \"sin_month\", \"cos_month\"]][start + self.T : start + self.T + self.S].values)\n        \"\"\"\n        # scalar is fit only to the input, to avoid the scaled values \"leaking\" information about the target range.\n        # scalar is fit only for humidity, as the timestamps are already scaled\n        # scalar input/output of shape: [n_samples, n_features].\n        scaler = self.transform\n\n        scaler.fit(_input[:,0].unsqueeze(-1))\n        \"\"\"\n        _input[:,0] = torch.tensor(scaler.transform(_input[:,0].unsqueeze(-1)).squeeze(-1))\n        target[:,0] = torch.tensor(scaler.transform(target[:,0].unsqueeze(-1)).squeeze(-1))\n        \"\"\"\n        # save the scalar to be used later when inverse translating the data for plotting.\n        dump(scaler, 'scalar_item.joblib')\n\n        return index_in, index_tar, _input, target, sensor_number","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\nThe architecture is based on the paper “Attention Is All You Need”. \nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.\n\"\"\"\n\nclass Transformer(nn.Module):\n    # d_model : number of features\n    def __init__(self,feature_size=7,num_layers=3,dropout=0):\n        super(Transformer, self).__init__()\n\n        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=7, dropout=dropout)\n        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n        self.decoder = nn.Linear(feature_size,1)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.1    \n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def _generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def forward(self, src, device):\n        \n        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n        output = self.transformer_encoder(src,mask)\n        output = self.decoder(output)\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\nThe architecture is based on the paper “Attention Is All You Need”. \nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.\n\"\"\"\n\nclass Transformer(nn.Module):\n    # d_model : number of features\n    def __init__(self,feature_size=7,num_layers=3,dropout=0):\n        super(Transformer, self).__init__()\n\n        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=7, dropout=dropout)\n        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n        self.decoder = nn.Linear(feature_size,1)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.1    \n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def _generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def forward(self, src, device):\n        \n        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n        output = self.transformer_encoder(src,mask)\n        output = self.decoder(output)\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%Y-%m-%d %H:%M:%S]\")\nlogger = logging.getLogger(__name__)\n\ndef transformer(dataloader, EPOCH, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n\n    device = torch.device(device)\n\n    model = Transformer().double().to(device)\n    optimizer = torch.optim.Adam(model.parameters())\n    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=200)\n    criterion = torch.nn.MSELoss()\n    best_model = \"\"\n    min_train_loss = float('inf')\n\n    for epoch in range(EPOCH + 1):\n\n        train_loss = 0\n        val_loss = 0\n\n        ## TRAIN -- TEACHER FORCING\n        model.train()\n        for index_in, index_tar, _input, target, sensor_number in dataloader: # for each data set \n        \n            optimizer.zero_grad()\n\n            # Shape of _input : [batch, input_length, feature]\n            # Desired input for model: [input_length, batch, feature]\n\n            src = _input.permute(1,0,2).double().to(device)[:-1,:,:] # torch.Size([24, 1, 7])\n            target = _input.permute(1,0,2).double().to(device)[1:,:,:] # src shifted by 1.\n            prediction = model(src, device) # torch.Size([24, 1, 7])\n            loss = criterion(prediction, target[:,:,0].unsqueeze(-1))\n            loss.backward()\n            optimizer.step()\n            # scheduler.step(loss.detach().item())\n            train_loss += loss.detach().item()\n\n        if train_loss < min_train_loss:\n            torch.save(model.state_dict(), path_to_save_model + f\"best_train_{epoch}.pth\")\n            torch.save(optimizer.state_dict(), path_to_save_model + f\"optimizer_{epoch}.pth\")\n            min_train_loss = train_loss\n            best_model = f\"best_train_{epoch}.pth\"\n\n\n        if epoch % 100 == 0: # Plot 1-Step Predictions\n\n            logger.info(f\"Epoch: {epoch}, Training loss: {train_loss}\")\n            scaler = load('scalar_item.joblib')\n            src_humidity = scaler.inverse_transform(src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n            target_humidity = scaler.inverse_transform(target[:,:,0].cpu()) #torch.Size([35, 1, 7])\n            prediction_humidity = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) #torch.Size([35, 1, 7])\n            plot_training(epoch, path_to_save_predictions, src_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n\n        train_loss /= len(dataloader)\n        log_loss(train_loss, path_to_save_loss, train=True)\n        \n    plot_loss(path_to_save_loss, train=True)\n    return best_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%Y-%m-%d %H:%M:%S]\")\nlogger = logging.getLogger(__name__)\n\ndef flip_from_probability(p):\n    return True if random.random() < p else False\n\ndef transformer(dataloader, EPOCH, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n\n    device = torch.device(device)\n\n    model = Transformer().double().to(device)\n    optimizer = torch.optim.Adam(model.parameters())\n    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=200)\n    criterion = torch.nn.MSELoss()\n    best_model = \"\"\n    min_train_loss = float('inf')\n\n    for epoch in range(EPOCH + 1):\n        train_loss = 0\n        val_loss = 0\n\n        ## TRAIN -- TEACHER FORCING\n        model.train()\n        for index_in, index_tar, _input, target, sensor_number in dataloader:\n        \n            # Shape of _input : [batch, input_length, feature]\n            # Desired input for model: [input_length, batch, feature]\n\n            optimizer.zero_grad()\n            src = _input.permute(1,0,2).double().to(device)[:-1,:,:] # torch.Size([24, 1, 7])\n            target = _input.permute(1,0,2).double().to(device)[1:,:,:] # src shifted by 1.\n            sampled_src = src[:1, :, :] #t0 torch.Size([1, 1, 7])\n\n            for i in range(len(target)-1):\n\n                prediction = model(sampled_src, device) # torch.Size([1xw, 1, 1])\n                # for p1, p2 in zip(params, model.parameters()):\n                #     if p1.data.ne(p2.data).sum() > 0:\n                #         ic(False)\n                # ic(True)\n                # ic(i, sampled_src[:,:,0], prediction)\n                # time.sleep(1)\n                \"\"\"\n                # to update model at every step\n                # loss = criterion(prediction, target[:i+1,:,:1])\n                # loss.backward()\n                # optimizer.step()\n                \"\"\"\n\n                if i < 24: # One day, enough data to make inferences about cycles\n                    prob_true_val = True\n                else:\n                    ## coin flip\n                    v = k/(k+math.exp(epoch/k)) # probability of heads/tails depends on the epoch, evolves with time.\n                    prob_true_val = flip_from_probability(v) # starts with over 95 % probability of true val for each flip in epoch 0.\n                    ## if using true value as new value\n\n                if prob_true_val: # Using true value as next value\n                    sampled_src = torch.cat((sampled_src.detach(), src[i+1, :, :].unsqueeze(0).detach()))\n                else: ## using prediction as new value\n                    positional_encodings_new_val = src[i+1,:,1:].unsqueeze(0)\n                    predicted_humidity = torch.cat((prediction[-1,:,:].unsqueeze(0), positional_encodings_new_val), dim=2)\n                    sampled_src = torch.cat((sampled_src.detach(), predicted_humidity.detach()))\n            \n            \"\"\"To update model after each sequence\"\"\"\n            loss = criterion(target[:-1,:,0].unsqueeze(-1), prediction)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.detach().item()\n\n        if train_loss < min_train_loss:\n            torch.save(model.state_dict(), path_to_save_model + f\"best_train_{epoch}.pth\")\n            torch.save(optimizer.state_dict(), path_to_save_model + f\"optimizer_{epoch}.pth\")\n            min_train_loss = train_loss\n            best_model = f\"best_train_{epoch}.pth\"\n\n\n        if epoch % 10 == 0: # Plot 1-Step Predictions\n\n            logger.info(f\"Epoch: {epoch}, Training loss: {train_loss}\")\n            scaler = load('scalar_item.joblib')\n            sampled_src_humidity = scaler.inverse_transform(sampled_src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n            src_humidity = scaler.inverse_transform(src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n            target_humidity = scaler.inverse_transform(target[:,:,0].cpu()) #torch.Size([35, 1, 7])\n            prediction_humidity = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) #torch.Size([35, 1, 7])\n            plot_training_3(epoch, path_to_save_predictions, src_humidity, sampled_src_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n\n        train_loss /= len(dataloader)\n        log_loss(train_loss, path_to_save_loss, train=True)\n        \n    plot_loss(path_to_save_loss, train=True)\n    return best_model","metadata":{},"execution_count":null,"outputs":[]}]}